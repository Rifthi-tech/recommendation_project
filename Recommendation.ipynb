{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QNg5kHPG-mK8",
        "1M540epC-g6z",
        "wqQiBTBw_G-5",
        "kO793eK7CPpH",
        "irVcWtXcDHDh"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1bGdMZBlEOpkmc5vkqduDdEfyfnjndl8N",
      "authorship_tag": "ABX9TyNfaTSviMHWJJgLI1TkA5jF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rifthi-tech/recommendation_project/blob/main/Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setting Up the Environment"
      ],
      "metadata": {
        "id": "QNg5kHPG-mK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Utilities\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "import os"
      ],
      "metadata": {
        "id": "YJ9ZV7_R-sYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import data"
      ],
      "metadata": {
        "id": "1M540epC-g6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Recommendation Project/test_sample_data.csv\")  # Replace with your actual file path\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "yCYCXWVGr55k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86fb2b01-cf9a-45cd-94d1-ce7b2e46f822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            uniq_id  \\\n",
            "0  c2d766ca982eca8304150849735ffef9   \n",
            "1  7f7036a6d550aaa89d34c77bd39a5e48   \n",
            "2  f449ec65dcbc041b6ae5e6a32717d01b   \n",
            "3  0973b37acd0c664e3de26e97e5571454   \n",
            "4  bc940ea42ee6bef5ac7cea3fb5cfbee7   \n",
            "\n",
            "                                         product_url  \\\n",
            "0  http://www.flipkart.com/alisha-solid-women-s-c...   \n",
            "1  http://www.flipkart.com/fabhomedecor-fabric-do...   \n",
            "2  http://www.flipkart.com/aw-bellies/p/itmeh4grg...   \n",
            "3  http://www.flipkart.com/alisha-solid-women-s-c...   \n",
            "4  http://www.flipkart.com/sicons-all-purpose-arn...   \n",
            "\n",
            "                            product_name  \\\n",
            "0    Alisha Solid Women's Cycling Shorts   \n",
            "1    FabHomeDecor Fabric Double Sofa Bed   \n",
            "2                             AW Bellies   \n",
            "3                            product_url   \n",
            "4  Sicons All Purpose Arnica Dog Shampoo   \n",
            "\n",
            "                               product_category_tree  Unnamed: 4  \\\n",
            "0  [\"Clothing >> Women's Clothing >> Lingerie, Sl...         NaN   \n",
            "1  [\"Furniture >> Living Room Furniture >> Sofa B...         NaN   \n",
            "2  [\"Footwear >> Women's Footwear >> Ballerinas >...         NaN   \n",
            "3  [\"Clothing >> Women's Clothing >> Lingerie, Sl...         NaN   \n",
            "4  [\"Pet Supplies >> Grooming >> Skin & Coat Care...         NaN   \n",
            "\n",
            "   retail_price                                              image  \\\n",
            "0         999.0  [\"http://img5a.flixcart.com/image/short/u/4/a/...   \n",
            "1       32157.0  [\"http://img6a.flixcart.com/image/sofa-bed/j/f...   \n",
            "2         999.0  [\"http://img5a.flixcart.com/image/shoe/7/z/z/r...   \n",
            "3         699.0  [\"http://img5a.flixcart.com/image/short/6/2/h/...   \n",
            "4         220.0  [\"http://img5a.flixcart.com/image/pet-shampoo/...   \n",
            "\n",
            "                                         description       product_rating  \\\n",
            "0  Key Features of Alisha Solid Women's Cycling S...  No rating available   \n",
            "1  FabHomeDecor Fabric Double Sofa Bed (Finish Co...  No rating available   \n",
            "2  Key Features of AW Bellies Sandals Wedges Heel...  No rating available   \n",
            "3  Key Features of Alisha Solid Women's Cycling S...  No rating available   \n",
            "4  Specifications of Sicons All Purpose Arnica Do...  No rating available   \n",
            "\n",
            "          brand                             product_specifications  \n",
            "0        Alisha  {\"product_specification\"=>[{\"key\"=>\"Number of ...  \n",
            "1  FabHomeDecor  {\"product_specification\"=>[{\"key\"=>\"Installati...  \n",
            "2            AW  {\"product_specification\"=>[{\"key\"=>\"Ideal For\"...  \n",
            "3        Alisha  {\"product_specification\"=>[{\"key\"=>\"Number of ...  \n",
            "4        Sicons  {\"product_specification\"=>[{\"key\"=>\"Pet Type\",...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data Cleaning"
      ],
      "metadata": {
        "id": "wqQiBTBw_G-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display original dataset info\n",
        "print(\"Original Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nOriginal Dataset Shape:\", df.shape)\n",
        "\n",
        "# Handle missing values\n",
        "# Fill missing numerical values with median\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "for col in numerical_cols:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# Fill missing categorical values with mode\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    if not df[col].mode().empty:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "    else:\n",
        "        df[col] = df[col].fillna(\"Unknown\")\n",
        "\n",
        "# Remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Ensure rating is between 0-5 (assuming rating scale is 0-5)\n",
        "if 'rating' in df.columns:\n",
        "    df['rating'] = df['rating'].clip(lower=0, upper=5)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nSuccess: Dataset cleaned successfully! Missing values handled and duplicates removed.\")\n"
      ],
      "metadata": {
        "id": "P34XFs9JsDjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8790087-e371-4fe2-cc5a-340d601fc81d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 11 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   uniq_id                 20000 non-null  object \n",
            " 1   product_url             20000 non-null  object \n",
            " 2   product_name            20000 non-null  object \n",
            " 3   product_category_tree   20000 non-null  object \n",
            " 4   Unnamed: 4              0 non-null      float64\n",
            " 5   retail_price            20000 non-null  float64\n",
            " 6   image                   20000 non-null  object \n",
            " 7   description             20000 non-null  object \n",
            " 8   product_rating          20000 non-null  object \n",
            " 9   brand                   20000 non-null  object \n",
            " 10  product_specifications  20000 non-null  object \n",
            "dtypes: float64(2), object(9)\n",
            "memory usage: 1.7+ MB\n",
            "None\n",
            "\n",
            "Original Dataset Shape: (20000, 11)\n",
            "\n",
            "Success: Dataset cleaned successfully! Missing values handled and duplicates removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Feature Extraction"
      ],
      "metadata": {
        "id": "kO793eK7CPpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def feature_extraction(products, ratings, purchases):\n",
        "    # Step 1: TF-IDF on product descriptions + categories\n",
        "    tfidf = TfidfVectorizer(stop_words='english')\n",
        "    product_features = tfidf.fit_transform(products['description'] + \" \" + products['category'])\n",
        "\n",
        "    # Step 2: User features from ratings\n",
        "    user_ratings = ratings.groupby('user_id').agg({\n",
        "        'rating': ['mean', 'count'],\n",
        "        'product_id': 'nunique'\n",
        "    }).reset_index()\n",
        "    user_ratings.columns = ['user_id', 'avg_rating', 'rating_count', 'unique_products_rated']\n",
        "\n",
        "    # Step 3: User features from purchases\n",
        "    user_purchases = purchases.groupby('user_id').agg({\n",
        "        'product_id': ['count', 'nunique'],\n",
        "        'purchase_date': 'max'\n",
        "    }).reset_index()\n",
        "    user_purchases.columns = ['user_id', 'total_purchases', 'unique_products_purchased', 'last_purchase_date']\n",
        "\n",
        "    # Step 4: Merge features\n",
        "    user_features = pd.merge(user_ratings, user_purchases, on='user_id', how='outer')\n",
        "    user_features.fillna(0, inplace=True)\n",
        "\n",
        "    # Step 5: Normalize selected columns\n",
        "    scaler = MinMaxScaler()\n",
        "    cols_to_normalize = ['avg_rating', 'rating_count', 'unique_products_rated',\n",
        "                         'total_purchases', 'unique_products_purchased']\n",
        "    user_features[cols_to_normalize] = scaler.fit_transform(user_features[cols_to_normalize])\n",
        "\n",
        "    return product_features, user_features, tfidf, scaler\n",
        "\n",
        "# ======== Main Execution ========\n",
        "if __name__ == \"__main__\":\n",
        "    # Load the data\n",
        "\n",
        "\n",
        "    # Run feature extraction\n",
        "    product_features, user_features, tfidf, scaler = feature_extraction(products, ratings, purchases)\n",
        "\n",
        "    # Display the user features (first 5 rows)\n",
        "    print(\"\\nExtracted User Features:\")\n",
        "    print(user_features.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwZbaQp9tk74",
        "outputId": "ec30cdd1-9e68-4c5f-f020-53d4a0bc8539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracted User Features:\n",
            "   user_id  avg_rating  rating_count  unique_products_rated  total_purchases  \\\n",
            "0        1         1.0           1.0                    1.0              1.0   \n",
            "1        2         0.0           1.0                    1.0              0.0   \n",
            "2        3         0.0           0.0                    0.0              1.0   \n",
            "\n",
            "   unique_products_purchased last_purchase_date  \n",
            "0                        1.0         2023-02-01  \n",
            "1                        0.0         2023-01-15  \n",
            "2                        1.0         2023-03-15  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Model Training"
      ],
      "metadata": {
        "id": "irVcWtXcDHDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_all_model_outputs(results):\n",
        "    \"\"\"Displays **all** trained model outputs with clear success messages and formatted data\"\"\"\n",
        "\n",
        "    try:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\" STARTING MODEL OUTPUT DISPLAY\".center(50))\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # 1. User similarity matrix\n",
        "        print(\"\\n STEP 1/4: Displaying User Similarity Matrix\")\n",
        "        user_sim_df = pd.DataFrame(results['user_similarity'])\n",
        "        print(f\" Success! User similarity matrix shape: {user_sim_df.shape}\")\n",
        "        print(\"Top 5x5 portion of User Similarity Matrix:\")\n",
        "        print(user_sim_df.iloc[:5, :5].to_markdown(tablefmt=\"grid\", floatfmt=\".2f\"))\n",
        "\n",
        "        # 2. Product similarity matrix\n",
        "        print(\"\\n STEP 2/4: Displaying Product Similarity Matrix\")\n",
        "        product_sim_df = pd.DataFrame(results['product_similarity'])\n",
        "        print(f\" Success! Product similarity matrix shape: {product_sim_df.shape}\")\n",
        "        print(\"Top 5x5 portion of Product Similarity Matrix:\")\n",
        "        print(product_sim_df.iloc[:5, :5].to_markdown(tablefmt=\"grid\", floatfmt=\".2f\"))\n",
        "\n",
        "        # 3. Purchase matrix\n",
        "        print(\"\\n STEP 3/4: Displaying Purchase Matrix\")\n",
        "        print(f\" Success! Purchase matrix shape: {results['purchase_matrix'].shape}\")\n",
        "        print(\"Sample of Purchase Matrix (first 5 rows):\")\n",
        "        print(results['purchase_matrix'].head().to_markdown(tablefmt=\"grid\"))\n",
        "\n",
        "        # 4. Hybrid model weights\n",
        "        print(\"\\n STEP 4/4: Displaying Hybrid Model Weights\")\n",
        "        weights_df = pd.DataFrame.from_dict(results['hybrid_weights'], orient='index', columns=['Weight'])\n",
        "        print(\" Success! Retrieved hybrid model weights\")\n",
        "        print(\"Hybrid Model Weights:\")\n",
        "        print(weights_df.to_markdown(tablefmt=\"grid\", floatfmt=\".2f\"))\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\" ALL MODEL OUTPUTS DISPLAYED SUCCESSFULLY!\".center(50))\n",
        "        print(\"=\"*50)\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"\\n Error: Missing expected key in results - {str(e)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n Unexpected error displaying outputs: {str(e)}\")\n",
        "\n",
        "# Example usage with test data\n",
        "if __name__ == \"__main__\":\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    # Create sample model results\n",
        "    model_results = {\n",
        "        'user_similarity': np.random.rand(10, 10),\n",
        "        'product_similarity': np.random.rand(15, 15),\n",
        "        'purchase_matrix': pd.DataFrame(np.random.randint(0, 2, (10, 15))),\n",
        "        'hybrid_weights': {\n",
        "            'content_weight': 0.4,\n",
        "            'collab_weight': 0.3,\n",
        "            'popularity_weight': 0.2,\n",
        "            'recency_weight': 0.1\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Call the function\n",
        "    display_all_model_outputs(model_results)\n"
      ],
      "metadata": {
        "id": "6fapTwe8DLSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4dc290c-bbac-49b3-974a-ae0b8e70876e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "           STARTING MODEL OUTPUT DISPLAY          \n",
            "==================================================\n",
            "\n",
            " STEP 1/4: Displaying User Similarity Matrix\n",
            " Success! User similarity matrix shape: (10, 10)\n",
            "Top 5x5 portion of User Similarity Matrix:\n",
            "+----+------+------+------+------+------+\n",
            "|    |    0 |    1 |    2 |    3 |    4 |\n",
            "+====+======+======+======+======+======+\n",
            "|  0 | 0.77 | 0.42 | 1.00 | 0.14 | 0.42 |\n",
            "+----+------+------+------+------+------+\n",
            "|  1 | 0.73 | 0.94 | 0.51 | 0.92 | 0.30 |\n",
            "+----+------+------+------+------+------+\n",
            "|  2 | 0.42 | 0.26 | 0.15 | 0.01 | 0.48 |\n",
            "+----+------+------+------+------+------+\n",
            "|  3 | 0.09 | 0.85 | 0.21 | 0.34 | 0.09 |\n",
            "+----+------+------+------+------+------+\n",
            "|  4 | 0.22 | 0.61 | 0.40 | 0.41 | 0.63 |\n",
            "+----+------+------+------+------+------+\n",
            "\n",
            " STEP 2/4: Displaying Product Similarity Matrix\n",
            " Success! Product similarity matrix shape: (15, 15)\n",
            "Top 5x5 portion of Product Similarity Matrix:\n",
            "+----+------+------+------+------+------+\n",
            "|    |    0 |    1 |    2 |    3 |    4 |\n",
            "+====+======+======+======+======+======+\n",
            "|  0 | 0.01 | 0.09 | 0.96 | 0.55 | 0.48 |\n",
            "+----+------+------+------+------+------+\n",
            "|  1 | 0.39 | 0.31 | 0.69 | 0.70 | 0.45 |\n",
            "+----+------+------+------+------+------+\n",
            "|  2 | 0.61 | 0.17 | 0.76 | 0.88 | 0.13 |\n",
            "+----+------+------+------+------+------+\n",
            "|  3 | 0.58 | 0.76 | 0.33 | 0.32 | 0.72 |\n",
            "+----+------+------+------+------+------+\n",
            "|  4 | 0.13 | 0.11 | 0.33 | 0.74 | 0.90 |\n",
            "+----+------+------+------+------+------+\n",
            "\n",
            " STEP 3/4: Displaying Purchase Matrix\n",
            " Success! Purchase matrix shape: (10, 15)\n",
            "Sample of Purchase Matrix (first 5 rows):\n",
            "+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+\n",
            "|    |   0 |   1 |   2 |   3 |   4 |   5 |   6 |   7 |   8 |   9 |   10 |   11 |   12 |   13 |   14 |\n",
            "+====+=====+=====+=====+=====+=====+=====+=====+=====+=====+=====+======+======+======+======+======+\n",
            "|  0 |   0 |   0 |   1 |   0 |   1 |   0 |   0 |   1 |   0 |   0 |    1 |    0 |    1 |    0 |    0 |\n",
            "+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+\n",
            "|  1 |   1 |   1 |   0 |   1 |   1 |   0 |   1 |   0 |   1 |   1 |    1 |    1 |    1 |    1 |    0 |\n",
            "+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+\n",
            "|  2 |   1 |   0 |   0 |   1 |   1 |   0 |   1 |   0 |   0 |   1 |    0 |    1 |    0 |    0 |    0 |\n",
            "+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+\n",
            "|  3 |   1 |   0 |   1 |   1 |   0 |   1 |   1 |   0 |   1 |   1 |    0 |    0 |    0 |    1 |    0 |\n",
            "+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+\n",
            "|  4 |   1 |   0 |   0 |   0 |   0 |   0 |   0 |   1 |   0 |   0 |    1 |    1 |    0 |    1 |    0 |\n",
            "+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+\n",
            "\n",
            " STEP 4/4: Displaying Hybrid Model Weights\n",
            " Success! Retrieved hybrid model weights\n",
            "Hybrid Model Weights:\n",
            "+-------------------+----------+\n",
            "|                   |   Weight |\n",
            "+===================+==========+\n",
            "| content_weight    |     0.40 |\n",
            "+-------------------+----------+\n",
            "| collab_weight     |     0.30 |\n",
            "+-------------------+----------+\n",
            "| popularity_weight |     0.20 |\n",
            "+-------------------+----------+\n",
            "| recency_weight    |     0.10 |\n",
            "+-------------------+----------+\n",
            "\n",
            "==================================================\n",
            "     ALL MODEL OUTPUTS DISPLAYED SUCCESSFULLY!    \n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Recommendation Functions"
      ],
      "metadata": {
        "id": "cyKZU0QaD_XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get recommendations based on different approaches\n",
        "def get_recommendations(method='hybrid', user_id=None, product_id=None):\n",
        "    if method == 'content':\n",
        "        if product_id is None:\n",
        "            print(\"Error: product_id required for content-based recommendations\")\n",
        "            return None\n",
        "        return content_based_recommendations(product_id)\n",
        "    elif method == 'collaborative':\n",
        "        if user_id is None:\n",
        "            print(\"Error: user_id required for collaborative recommendations\")\n",
        "            return None\n",
        "        return collaborative_user_based(user_id)\n",
        "    elif method == 'hybrid':\n",
        "        if user_id is None or product_id is None:\n",
        "            print(\"Error: both user_id and product_id required for hybrid recommendations\")\n",
        "            return None\n",
        "        return hybrid_recommendations(user_id, product_id)\n",
        "    elif method == 'rating':\n",
        "        return rating_based_recommendations()\n",
        "    elif method == 'purchase':\n",
        "        return purchase_based_recommendations()\n",
        "    else:\n",
        "        print(\"Error: Invalid method. Choose from: content, collaborative, hybrid, rating, purchase\")\n",
        "        return None\n",
        "\n",
        "# Example usage:\n",
        "    content_rec = get_recommendations(method='content', product_id=123)\n",
        "    collab_rec = get_recommendations(method='collaborative', user_id=456)\n",
        "    hybrid_rec = get_recommendations(method='hybrid', user_id=456, product_id=123)\n",
        "    top_rated = get_recommendations(method='rating')\n",
        "    top_purchased = get_recommendations(method='purchase')\n",
        "\n",
        "print(\"\\nSuccess: Recommendation functions created successfully!\")"
      ],
      "metadata": {
        "id": "zapbEcvqED3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e211a9-ccc8-4517-b790-259ac9929fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Success: Recommendation functions created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.Export data"
      ],
      "metadata": {
        "id": "dP9nKuBVyEFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "file_path = '/content/drive/MyDrive/Recommendation Project/test_sample_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Normalize column names: lowercase and trim spaces\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Create mapping from your actual columns to our required columns\n",
        "column_mapping = {\n",
        "    'product_name': 'name',  # This is the key fix - mapping product_name to name\n",
        "    # These columns might exist in your data:\n",
        "    'uniq_id': 'id',\n",
        "    'retail_price': 'price',\n",
        "    'product_rating': 'rating',\n",
        "    'product_category_tree': 'category',\n",
        "    # These columns already match or don't need renaming:\n",
        "    'id': 'id',\n",
        "    'price': 'price',\n",
        "    'rating': 'rating',\n",
        "    'category': 'category',\n",
        "    'image': 'image',\n",
        "    'description': 'description'\n",
        "}\n",
        "\n",
        "# Rename columns - only keep mappings that exist in the dataframe\n",
        "final_mapping = {k: v for k, v in column_mapping.items() if k in df.columns}\n",
        "df = df.rename(columns=final_mapping)\n",
        "\n",
        "# Output directory in Google Drive\n",
        "output_dir = \"/content/drive/MyDrive/Recommendation Project/Output/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define required columns\n",
        "required_columns = ['id', 'image', 'name', 'description', 'price', 'rating', 'category']\n",
        "\n",
        "# Verify which required columns we have\n",
        "available_columns = [col for col in required_columns if col in df.columns]\n",
        "missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "\n",
        "if missing_columns:\n",
        "    print(f\"⚠️ Warning: The following required columns are missing: {missing_columns}\")\n",
        "    print(\"Available columns in your data:\", list(df.columns))\n",
        "else:\n",
        "    print(\"✅ All required columns are present in the data\")\n",
        "\n",
        "# Only proceed with available columns\n",
        "if available_columns:\n",
        "    # Step 1: Drop rows with missing values in available required columns\n",
        "    processed_df = df.dropna(subset=available_columns)\n",
        "\n",
        "    # Step 2: Drop rows with empty or whitespace-only values\n",
        "    for col in available_columns:\n",
        "        processed_df = processed_df[processed_df[col].astype(str).str.strip() != '']\n",
        "\n",
        "    # Step 3: Clean category column if it exists (remove brackets and quotes)\n",
        "    if 'category' in processed_df.columns:\n",
        "        processed_df['category'] = processed_df['category'].str.replace(r'[\\[\\]\"]', '', regex=True)\n",
        "        processed_df['category'] = processed_df['category'].str.split(',').str[0].str.strip()\n",
        "\n",
        "    # Step 4: Keep only available required columns\n",
        "    processed_df = processed_df[available_columns]\n",
        "\n",
        "    # Step 5: Save to CSV\n",
        "    processed_data_path = os.path.join(output_dir, 'processed_recommendation_data.csv')\n",
        "    try:\n",
        "        processed_df.to_csv(processed_data_path, index=False)\n",
        "        print(\"\\n✅ Processed data saved successfully to:\", processed_data_path)\n",
        "        print(\"📦 Total valid products saved:\", len(processed_df))\n",
        "\n",
        "        # Preview the result\n",
        "        print(\"\\n📋 Preview of saved data:\")\n",
        "        print(processed_df.head())\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error saving data:\", str(e))\n",
        "else:\n",
        "    print(\"❌ Error: None of the required columns were found in the data\")"
      ],
      "metadata": {
        "id": "ioF1B5CDUVcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54231c29-c079-4145-8eff-a9a3803ce76c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All required columns are present in the data\n",
            "\n",
            "✅ Processed data saved successfully to: /content/drive/MyDrive/Recommendation Project/Output/processed_recommendation_data.csv\n",
            "📦 Total valid products saved: 19917\n",
            "\n",
            "📋 Preview of saved data:\n",
            "                                 id  \\\n",
            "0  c2d766ca982eca8304150849735ffef9   \n",
            "1  7f7036a6d550aaa89d34c77bd39a5e48   \n",
            "2  f449ec65dcbc041b6ae5e6a32717d01b   \n",
            "3  0973b37acd0c664e3de26e97e5571454   \n",
            "4  bc940ea42ee6bef5ac7cea3fb5cfbee7   \n",
            "\n",
            "                                               image  \\\n",
            "0  [\"http://img5a.flixcart.com/image/short/u/4/a/...   \n",
            "1  [\"http://img6a.flixcart.com/image/sofa-bed/j/f...   \n",
            "2  [\"http://img5a.flixcart.com/image/shoe/7/z/z/r...   \n",
            "3  [\"http://img5a.flixcart.com/image/short/6/2/h/...   \n",
            "4  [\"http://img5a.flixcart.com/image/pet-shampoo/...   \n",
            "\n",
            "                                    name  \\\n",
            "0    Alisha Solid Women's Cycling Shorts   \n",
            "1    FabHomeDecor Fabric Double Sofa Bed   \n",
            "2                             AW Bellies   \n",
            "3                            product_url   \n",
            "4  Sicons All Purpose Arnica Dog Shampoo   \n",
            "\n",
            "                                         description    price  \\\n",
            "0  Key Features of Alisha Solid Women's Cycling S...    999.0   \n",
            "1  FabHomeDecor Fabric Double Sofa Bed (Finish Co...  32157.0   \n",
            "2  Key Features of AW Bellies Sandals Wedges Heel...    999.0   \n",
            "3  Key Features of Alisha Solid Women's Cycling S...    699.0   \n",
            "4  Specifications of Sicons All Purpose Arnica Do...    220.0   \n",
            "\n",
            "                rating                                           category  \n",
            "0  No rating available           Clothing >> Women's Clothing >> Lingerie  \n",
            "1  No rating available  Furniture >> Living Room Furniture >> Sofa Bed...  \n",
            "2  No rating available  Footwear >> Women's Footwear >> Ballerinas >> ...  \n",
            "3  No rating available           Clothing >> Women's Clothing >> Lingerie  \n",
            "4  No rating available  Pet Supplies >> Grooming >> Skin & Coat Care >...  \n"
          ]
        }
      ]
    }
  ]
}